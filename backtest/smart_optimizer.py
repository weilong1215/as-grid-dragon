"""
æ™ºèƒ½åƒæ•¸å„ªåŒ–å™¨æ¨¡çµ„
===================

åŸºæ–¼ Optuna æ¡†æ¶çš„å…ˆé€²å„ªåŒ–ç³»çµ±ï¼š
- TPE (Tree-structured Parzen Estimator) è²è‘‰æ–¯å„ªåŒ–
- å¤šç›®æ¨™å„ªåŒ– (Sharpe, Sortino, MaxDrawdown)
- åƒæ•¸é‡è¦æ€§åˆ†æ
- æ—©æœŸåœæ­¢ç­–ç•¥
- å¯è¦–åŒ–æ­·å²è¿½è¹¤

åƒè€ƒ:
- Optuna: https://optuna.org
- Freqtrade Hyperopt
- ç¶²æ ¼äº¤æ˜“è«–æ–‡å„ªåŒ–æŠ€è¡“
"""

import pandas as pd
import numpy as np
from typing import List, Dict, Optional, Callable, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
from concurrent.futures import ProcessPoolExecutor
import logging
import time
import json
from pathlib import Path

try:
    import optuna
    from optuna.samplers import TPESampler, NSGAIISampler, NSGAIIISampler
    from optuna.pruners import MedianPruner, HyperbandPruner
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False
    optuna = None

from .config import Config
from .backtester import GridBacktester, BacktestResult


class OptimizationObjective(Enum):
    """å„ªåŒ–ç›®æ¨™"""
    RETURN = "return"           # æ”¶ç›Šç‡
    SHARPE = "sharpe"           # Sharpe Ratio
    SORTINO = "sortino"         # Sortino Ratio (åªè¨ˆç®—ä¸‹è¡Œé¢¨éšª)
    CALMAR = "calmar"           # Calmar Ratio (æ”¶ç›Š/æœ€å¤§å›æ’¤)
    PROFIT_FACTOR = "profit_factor"  # ç›ˆè™§æ¯”
    RISK_ADJUSTED = "risk_adjusted"  # é¢¨éšªèª¿æ•´æ”¶ç›Š (æ”¶ç›Š - 2*å›æ’¤)
    MULTI_OBJECTIVE = "multi"   # å¤šç›®æ¨™ (Pareto å„ªåŒ–)


class OptimizationMethod(Enum):
    """å„ªåŒ–æ–¹æ³•"""
    GRID_SEARCH = "grid"        # ç¶²æ ¼æœç´¢ (èˆŠæ–¹æ³•)
    TPE = "tpe"                 # Tree-structured Parzen Estimator
    CMA_ES = "cma_es"           # CMA-ES æ¼”åŒ–ç­–ç•¥
    NSGA_II = "nsga_ii"         # å¤šç›®æ¨™æ¼”åŒ–ç®—æ³• NSGA-II
    NSGA_III = "nsga_iii"       # å¤šç›®æ¨™æ¼”åŒ–ç®—æ³• NSGA-III


class TradingMode(Enum):
    """
    äº¤æ˜“æ¨¡å¼ - æ±ºå®šå„ªåŒ–åƒæ•¸ç¯„åœ

    æ ¹æ“šé æœŸæŒå€‰é€±æœŸé¸æ“‡ä¸åŒæ¨¡å¼ï¼š
    - HIGH_FREQ: æ¬¡é«˜é »åˆ·é‡ (2-7å¤©)
    - SWING: æ³¢å‹•æ¨¡å¼ (1é€±-1æœˆ)
    - LONG_CYCLE: å¤§é€±æœŸæ¨¡å¼ (1æœˆä»¥ä¸Š)
    """
    HIGH_FREQ = "high_freq"     # ğŸš€ æ¬¡é«˜é »ï¼šå°é–“è·ã€é«˜é »åˆ·é‡
    SWING = "swing"             # ğŸ“Š æ³¢å‹•ï¼šä¸­ç­‰é–“è·ã€æ•æ‰æ³¢æ®µ
    LONG_CYCLE = "long_cycle"   # ğŸŒŠ å¤§é€±æœŸï¼šå¤§é–“è·ã€é•·æœŸæŒæœ‰


# å„æ¨¡å¼çš„åƒæ•¸ç¯„åœé è¨­
# è¨­è¨ˆåŸå‰‡:
#   1. take_profit_spacing å¿…é ˆ > 0.15% (è¦†è“‹ 0.08% æ‰‹çºŒè²» + åˆç†åˆ©æ½¤)
#   2. grid_spacing > take_profit_spacing Ã— 1.2 (ç•™å‡ºæ­¢ç›ˆç©ºé–“)
#   3. ç¯„åœè¦å¤ å¯¬ï¼Œè®“å„ªåŒ–å™¨æœ‰è¶³å¤ ç©ºé–“æ¢ç´¢
#   4. ä¸‰ç¨®æ¨¡å¼æœ‰é©åº¦é‡ç–Šï¼Œå…è¨±åœ¨é‚Šç•Œæ‰¾åˆ°æœ€ä½³é»
MODE_PARAM_BOUNDS = {
    TradingMode.HIGH_FREQ: {
        # æ¬¡é«˜é »ï¼šå°é–“è·é«˜é »äº¤æ˜“ï¼Œå¿«é€Ÿç´¯ç©å°åˆ©æ½¤
        # é¢¨éšªï¼šå–®é‚Šè¡Œæƒ…å®¹æ˜“å¿«é€Ÿç´¯ç©å¤§å€‰ä½
        "take_profit_spacing": (0.0015, 0.0050),   # 0.15% ~ 0.50%
        "grid_spacing": (0.0020, 0.0080),          # 0.20% ~ 0.80%
        "limit_multiplier": (2.0, 8.0),            # è¼ƒæ—©è§¸ç™¼åŠ å€å‡ºè²¨
        "threshold_multiplier": (6.0, 20.0),       # è¼ƒæ—©è§¸ç™¼è£æ­»ï¼Œæ§åˆ¶é¢¨éšª
    },
    TradingMode.SWING: {
        # æ³¢å‹•æ¨¡å¼ï¼šä¸­ç­‰é–“è·ï¼Œæ•æ‰æ³¢æ®µåˆ©æ½¤
        # å¹³è¡¡äº¤æ˜“é »ç‡èˆ‡å–®ç­†åˆ©æ½¤
        "take_profit_spacing": (0.0030, 0.0150),   # 0.30% ~ 1.50%
        "grid_spacing": (0.0050, 0.0300),          # 0.50% ~ 3.00%
        "limit_multiplier": (3.0, 15.0),           # ä¸­ç­‰åŠ å€è§¸ç™¼
        "threshold_multiplier": (10.0, 40.0),      # ä¸­ç­‰è£æ­»é–¾å€¼
    },
    TradingMode.LONG_CYCLE: {
        # å¤§é€±æœŸï¼šå¤§é–“è·ï¼ŒåªæŠ“å¤§æ³¢å‹•
        # å¯æ‰¿å—è¼ƒå¤§å€‰ä½ï¼Œç­‰å¾…è¼ƒå¤§åå½ˆ
        "take_profit_spacing": (0.0080, 0.0500),   # 0.80% ~ 5.00%
        "grid_spacing": (0.0150, 0.1000),          # 1.50% ~ 10.00%
        "limit_multiplier": (5.0, 30.0),           # å…è¨±è¼ƒå¤§å€‰ä½ç´¯ç©
        "threshold_multiplier": (15.0, 80.0),      # é«˜å®¹å¿åº¦ï¼Œç­‰å¾…å¤§åå½ˆ
    },
}

# æ¨¡å¼é¡¯ç¤ºè³‡è¨Š
MODE_INFO = {
    TradingMode.HIGH_FREQ: {
        "name": "ğŸš€ æ¬¡é«˜é »",
        "description": "å°é–“è·ã€é«˜é »åˆ·é‡",
        "timeframe": "2-7 å¤©",
        "best_for": "ç©©å®šå¹£å°ã€ä½æ³¢å‹•è¡Œæƒ…",
    },
    TradingMode.SWING: {
        "name": "ğŸ“Š æ³¢å‹•",
        "description": "ä¸­ç­‰é–“è·ã€æ•æ‰æ³¢æ®µ",
        "timeframe": "1é€± - 1æœˆ",
        "best_for": "ä¸€èˆ¬å±±å¯¨å¹£ã€ä¸­ç­‰æ³¢å‹•",
    },
    TradingMode.LONG_CYCLE: {
        "name": "ğŸŒŠ å¤§é€±æœŸ",
        "description": "å¤§é–“è·ã€é•·æœŸæŒæœ‰",
        "timeframe": "1æœˆä»¥ä¸Š",
        "best_for": "é«˜æ³¢å‹•å¹£ç¨®ã€è¶¨å‹¢å¸‚å ´",
    },
}


@dataclass
class TrialResult:
    """å–®æ¬¡è©¦é©—çµæœ"""
    trial_number: int
    params: Dict[str, float]
    metrics: Dict[str, float]
    objective_value: float
    duration: float

    def to_dict(self) -> dict:
        return {
            "trial": self.trial_number,
            **{f"param_{k}": v for k, v in self.params.items()},
            **self.metrics,
            "objective": self.objective_value,
            "duration_s": self.duration
        }


@dataclass
class SmartOptimizationResult:
    """æ™ºèƒ½å„ªåŒ–çµæœ"""
    best_params: Dict[str, float]
    best_metrics: Dict[str, float]
    best_objective: float
    all_trials: List[TrialResult]
    param_importance: Dict[str, float]
    pareto_front: Optional[List[Dict]] = None  # å¤šç›®æ¨™å„ªåŒ–çš„ Pareto å‰æ²¿
    convergence_history: List[float] = field(default_factory=list)
    optimization_time: float = 0.0
    n_trials: int = 0
    method: str = "tpe"
    objective_type: str = "sharpe"

    def to_dataframe(self) -> pd.DataFrame:
        """è½‰æ›ç‚º DataFrame"""
        rows = [t.to_dict() for t in self.all_trials]
        return pd.DataFrame(rows)

    def get_top_n(self, n: int = 5) -> pd.DataFrame:
        """ç²å– Top N çµæœ"""
        df = self.to_dataframe()
        return df.nlargest(n, 'objective')

    def __str__(self) -> str:
        return (
            f"æ™ºèƒ½å„ªåŒ–çµæœ\n"
            f"{'='*50}\n"
            f"æ–¹æ³•: {self.method.upper()}\n"
            f"ç›®æ¨™: {self.objective_type}\n"
            f"è©¦é©—æ•¸: {self.n_trials}\n"
            f"è€—æ™‚: {self.optimization_time:.1f}s\n"
            f"\næœ€ä½³åƒæ•¸:\n"
            f"  æ­¢ç›ˆé–“è·: {self.best_params.get('take_profit_spacing', 0)*100:.3f}%\n"
            f"  è£œå€‰é–“è·: {self.best_params.get('grid_spacing', 0)*100:.3f}%\n"
            f"  æ­¢ç›ˆåŠ å€å€æ•¸: {self.best_params.get('limit_multiplier', 5.0):.1f}x\n"
            f"  è£æ­»æ¨¡å¼å€æ•¸: {self.best_params.get('threshold_multiplier', 14.0):.1f}x\n"
            f"\næœ€ä½³ç¸¾æ•ˆ:\n"
            f"  ç›®æ¨™å€¼: {self.best_objective:.4f}\n"
            f"  æ”¶ç›Šç‡: {self.best_metrics.get('return_pct', 0)*100:.2f}%\n"
            f"  Sharpe: {self.best_metrics.get('sharpe_ratio', 0):.3f}\n"
            f"  æœ€å¤§å›æ’¤: {self.best_metrics.get('max_drawdown', 0)*100:.2f}%\n"
            f"  å‹ç‡: {self.best_metrics.get('win_rate', 0)*100:.1f}%\n"
            f"\nåƒæ•¸é‡è¦æ€§:\n" +
            "\n".join([f"  {k}: {v*100:.1f}%" for k, v in
                      sorted(self.param_importance.items(), key=lambda x: -x[1])])
        )


class SmartOptimizer:
    """
    æ™ºèƒ½åƒæ•¸å„ªåŒ–å™¨

    ä½¿ç”¨ Optuna æ¡†æ¶å¯¦ç¾:
    - è²è‘‰æ–¯å„ªåŒ– (TPE)
    - å¤šç›®æ¨™å„ªåŒ– (NSGA-II/III)
    - åƒæ•¸é‡è¦æ€§åˆ†æ
    - æ—©æœŸåœæ­¢

    å„ªå‹¢:
    - æ¯”ç¶²æ ¼æœç´¢å¿« 5-10 å€
    - è‡ªå‹•æ¢ç´¢æœ€æœ‰æ½›åŠ›çš„åƒæ•¸å€åŸŸ
    - æ”¯æŒå¤šç›®æ¨™æ¬Šè¡¡
    """

    # åƒæ•¸é‚Šç•Œå®šç¾© (æœªæŒ‡å®šæ¨¡å¼æ™‚çš„é è¨­ç¯„åœ)
    # æ¶µè“‹æ‰€æœ‰æ¨¡å¼çš„åˆç†ç¯„åœ
    DEFAULT_PARAM_BOUNDS = {
        "take_profit_spacing": (0.0015, 0.0300),  # 0.15% ~ 3.00%
        "grid_spacing": (0.0020, 0.0600),         # 0.20% ~ 6.00%
        "limit_multiplier": (2.0, 20.0),          # æ­¢ç›ˆåŠ å€å€æ•¸ 2x ~ 20x
        "threshold_multiplier": (6.0, 50.0),      # è£æ­»æ¨¡å¼å€æ•¸ 6x ~ 50x
    }

    # å›ºå®šåƒæ•¸ (ä¸å„ªåŒ–)
    DEFAULT_FIXED_PARAMS = {
        "leverage": 20,           # æ§“æ¡¿å›ºå®š
        "max_positions": 50,
        "max_drawdown": 0.5,
        "fee_pct": 0.0004,
    }

    def __init__(
        self,
        df: pd.DataFrame,
        base_config: Config = None,
        param_bounds: Dict[str, Tuple[float, float]] = None,
        fixed_params: Dict[str, Any] = None,
        trading_mode: TradingMode = None,
        logger: logging.Logger = None
    ):
        """
        åˆå§‹åŒ–å„ªåŒ–å™¨

        Args:
            df: Kç·šæ•¸æ“š
            base_config: åŸºç¤é…ç½®
            param_bounds: åƒæ•¸ç¯„åœ {name: (min, max)}ï¼Œå¦‚æœæŒ‡å®š trading_mode å‰‡å¿½ç•¥
            fixed_params: å›ºå®šåƒæ•¸
            trading_mode: äº¤æ˜“æ¨¡å¼ (HIGH_FREQ/SWING/LONG_CYCLE)
            logger: æ—¥èªŒå™¨
        """
        self.df = df
        self.base_config = base_config or Config()
        self.logger = logger or logging.getLogger("SmartOptimizer")

        # æ ¹æ“šäº¤æ˜“æ¨¡å¼è¨­ç½®åƒæ•¸ç¯„åœ
        self.trading_mode = trading_mode
        if trading_mode is not None:
            self.param_bounds = MODE_PARAM_BOUNDS[trading_mode].copy()
            self.logger.info(f"ä½¿ç”¨äº¤æ˜“æ¨¡å¼: {MODE_INFO[trading_mode]['name']}")
        else:
            self.param_bounds = param_bounds or self.DEFAULT_PARAM_BOUNDS.copy()

        self.fixed_params = fixed_params or self.DEFAULT_FIXED_PARAMS.copy()

        # å„ªåŒ–ç‹€æ…‹
        self._study = None
        self._trials: List[TrialResult] = []
        self._best_value = float('-inf')
        self._convergence = []

    def _create_config(self, params: Dict) -> Config:
        """æ ¹æ“šåƒæ•¸å‰µå»ºé…ç½®"""
        # ç²å– multiplier åƒæ•¸
        limit_mult = params.get('limit_multiplier', self.base_config.limit_multiplier)
        threshold_mult = params.get('threshold_multiplier', self.base_config.threshold_multiplier)

        # è¨ˆç®— position_limit å’Œ position_threshold
        # é€™è£¡ä½¿ç”¨ initial_quantity ä¾†è¨ˆç®—ï¼Œå¦‚æœæœªè¨­ç½®å‰‡ä½¿ç”¨é è¨­å€¼
        initial_qty = self.base_config.initial_quantity
        if initial_qty <= 0:
            # å¦‚æœæ²’æœ‰è¨­ç½® initial_quantityï¼Œä½¿ç”¨ order_value / ä¼°è¨ˆåƒ¹æ ¼
            # é€™è£¡ä½¿ç”¨ df çš„ä¸­é–“åƒ¹æ ¼ä¼°è¨ˆ
            mid_price = self.df['close'].median() if len(self.df) > 0 else 1.0
            initial_qty = self.base_config.order_value / mid_price

        position_limit = initial_qty * limit_mult
        position_threshold = initial_qty * threshold_mult

        return Config(
            symbol=self.base_config.symbol,
            initial_balance=self.base_config.initial_balance,
            order_value=self.base_config.order_value,
            initial_quantity=self.base_config.initial_quantity,
            leverage=int(self.fixed_params.get('leverage', self.base_config.leverage)),
            take_profit_spacing=params.get('take_profit_spacing', self.base_config.take_profit_spacing),
            grid_spacing=params.get('grid_spacing', self.base_config.grid_spacing),
            direction=self.base_config.direction,
            max_drawdown=self.fixed_params.get('max_drawdown', 0.5),
            max_positions=self.fixed_params.get('max_positions', 50),
            fee_pct=self.fixed_params.get('fee_pct', 0.0004),
            position_threshold=position_threshold,
            position_limit=position_limit,
            limit_multiplier=limit_mult,
            threshold_multiplier=threshold_mult,
        )

    def _run_backtest(self, params: Dict) -> BacktestResult:
        """åŸ·è¡Œå–®æ¬¡å›æ¸¬"""
        config = self._create_config(params)
        bt = GridBacktester(self.df.copy(), config)
        return bt.run()

    def _calculate_sortino_ratio(self, equity_curve: List[Tuple]) -> float:
        """è¨ˆç®— Sortino Ratio (åªè€ƒæ…®ä¸‹è¡Œé¢¨éšª)"""
        if len(equity_curve) < 2:
            return 0.0

        returns = []
        for i in range(1, len(equity_curve)):
            prev_equity = equity_curve[i-1][2]
            curr_equity = equity_curve[i][2]
            if prev_equity > 0:
                returns.append((curr_equity - prev_equity) / prev_equity)

        if not returns:
            return 0.0

        avg_return = np.mean(returns)
        downside_returns = [r for r in returns if r < 0]

        if not downside_returns:
            return float('inf') if avg_return > 0 else 0.0

        downside_std = np.std(downside_returns)
        if downside_std == 0:
            return float('inf') if avg_return > 0 else 0.0

        # å¹´åŒ– Sortino
        return (avg_return / downside_std) * np.sqrt(252)

    def _calculate_calmar_ratio(self, return_pct: float, max_drawdown: float) -> float:
        """è¨ˆç®— Calmar Ratio"""
        if max_drawdown == 0 or max_drawdown < 0.001:
            return float('inf') if return_pct > 0 else 0.0
        return return_pct / max_drawdown

    def _calculate_objective(
        self,
        result: BacktestResult,
        objective: OptimizationObjective
    ) -> float:
        """è¨ˆç®—ç›®æ¨™å‡½æ•¸å€¼"""

        if objective == OptimizationObjective.RETURN:
            return result.return_pct

        elif objective == OptimizationObjective.SHARPE:
            return result.sharpe_ratio

        elif objective == OptimizationObjective.SORTINO:
            return self._calculate_sortino_ratio(result.equity_curve)

        elif objective == OptimizationObjective.CALMAR:
            return self._calculate_calmar_ratio(result.return_pct, result.max_drawdown)

        elif objective == OptimizationObjective.PROFIT_FACTOR:
            return min(result.profit_factor, 10.0)  # é™åˆ¶æœ€å¤§å€¼

        elif objective == OptimizationObjective.RISK_ADJUSTED:
            # é¢¨éšªèª¿æ•´æ”¶ç›Š: æ”¶ç›Š - 2*å›æ’¤
            return result.return_pct - 2 * result.max_drawdown

        else:
            return result.sharpe_ratio

    def _optuna_objective(
        self,
        trial: 'optuna.Trial',
        objective_type: OptimizationObjective
    ) -> float:
        """Optuna ç›®æ¨™å‡½æ•¸"""
        start_time = time.time()

        # å¾ Optuna æ¡æ¨£åƒæ•¸
        params = {}

        # ç²å–åƒæ•¸ç¯„åœ
        tp_min, tp_max = self.param_bounds.get('take_profit_spacing', (0.001, 0.015))
        gs_min, gs_max = self.param_bounds.get('grid_spacing', (0.002, 0.025))

        # é™åˆ¶ tp_maxï¼Œç¢ºä¿ tp * 1.1 < gs_max (ç•™ç©ºé–“çµ¦ grid_spacing)
        tp_max_safe = min(tp_max, gs_max / 1.15)
        if tp_max_safe < tp_min:
            tp_max_safe = tp_min * 2  # è‡³å°‘æœ‰ä¸€äº›ç¯„åœ

        # æ­¢ç›ˆé–“è·
        params['take_profit_spacing'] = trial.suggest_float(
            'take_profit_spacing', tp_min, tp_max_safe, log=True
        )

        # è£œå€‰é–“è· (å¿…é ˆå¤§æ–¼æ­¢ç›ˆé–“è·)
        # å‹•æ…‹èª¿æ•´ä¸‹é™ (ç¢ºä¿ gs > tp)
        gs_lower = max(gs_min, params['take_profit_spacing'] * 1.1)

        # é‚Šç•Œæª¢æŸ¥ï¼šå¦‚æœä¸‹é™è¶…éä¸Šé™ï¼Œè·³éæ­¤ trial
        if gs_lower >= gs_max:
            raise optuna.TrialPruned(f"Invalid param range: gs_lower={gs_lower:.4f} >= gs_max={gs_max:.4f}")

        params['grid_spacing'] = trial.suggest_float(
            'grid_spacing', gs_lower, gs_max, log=True
        )

        # æ­¢ç›ˆåŠ å€å€æ•¸ (limit_multiplier)
        if 'limit_multiplier' in self.param_bounds:
            lm_min, lm_max = self.param_bounds['limit_multiplier']
            params['limit_multiplier'] = trial.suggest_float(
                'limit_multiplier', lm_min, lm_max
            )
        else:
            params['limit_multiplier'] = self.base_config.limit_multiplier

        # è£æ­»æ¨¡å¼å€æ•¸ (threshold_multiplier)
        # ç¢ºä¿ threshold_multiplier > limit_multiplier (è£æ­»é–¾å€¼æ‡‰å¤§æ–¼åŠ å€é–¾å€¼)
        if 'threshold_multiplier' in self.param_bounds:
            tm_min, tm_max = self.param_bounds['threshold_multiplier']
            # å‹•æ…‹ä¸‹é™ï¼šè‡³å°‘æ¯” limit_multiplier å¤§ 1.5 å€
            tm_lower = max(tm_min, params['limit_multiplier'] * 1.5)
            if tm_lower >= tm_max:
                tm_lower = tm_min  # å¦‚æœä¸‹é™è¶…éä¸Šé™ï¼Œå›é€€åˆ°åŸå§‹ä¸‹é™
            params['threshold_multiplier'] = trial.suggest_float(
                'threshold_multiplier', tm_lower, tm_max
            )
        else:
            params['threshold_multiplier'] = self.base_config.threshold_multiplier

        # åŸ·è¡Œå›æ¸¬
        try:
            result = self._run_backtest(params)
            objective_value = self._calculate_objective(result, objective_type)

            # è™•ç†ç„¡æ•ˆå€¼
            if np.isnan(objective_value) or np.isinf(objective_value):
                objective_value = -1e6

            # è¨˜éŒ„è©¦é©—
            duration = time.time() - start_time
            metrics = {
                'return_pct': result.return_pct,
                'sharpe_ratio': result.sharpe_ratio,
                'max_drawdown': result.max_drawdown,
                'trades_count': result.trades_count,
                'win_rate': result.win_rate,
                'profit_factor': min(result.profit_factor, 100),
            }

            trial_result = TrialResult(
                trial_number=trial.number,
                params=params.copy(),
                metrics=metrics,
                objective_value=objective_value,
                duration=duration
            )
            self._trials.append(trial_result)

            # æ›´æ–°æ”¶æ–‚æ­·å²
            if objective_value > self._best_value:
                self._best_value = objective_value
            self._convergence.append(self._best_value)

            return objective_value

        except Exception as e:
            self.logger.warning(f"Trial {trial.number} å¤±æ•—: {e}")
            return -1e6

    def _multi_objective(
        self,
        trial: 'optuna.Trial'
    ) -> Tuple[float, float, float]:
        """å¤šç›®æ¨™å„ªåŒ–å‡½æ•¸ (æœ€å¤§åŒ– Sharpe, æœ€å°åŒ–å›æ’¤, æœ€å¤§åŒ–æ”¶ç›Š)"""
        start_time = time.time()

        params = {}
        tp_min, tp_max = self.param_bounds.get('take_profit_spacing', (0.001, 0.015))
        params['take_profit_spacing'] = trial.suggest_float(
            'take_profit_spacing', tp_min, tp_max, log=True
        )

        gs_min, gs_max = self.param_bounds.get('grid_spacing', (0.002, 0.025))
        gs_lower = max(gs_min, params['take_profit_spacing'] * 1.2)
        params['grid_spacing'] = trial.suggest_float(
            'grid_spacing', gs_lower, gs_max, log=True
        )

        # æ­¢ç›ˆåŠ å€å€æ•¸ (limit_multiplier)
        if 'limit_multiplier' in self.param_bounds:
            lm_min, lm_max = self.param_bounds['limit_multiplier']
            params['limit_multiplier'] = trial.suggest_float(
                'limit_multiplier', lm_min, lm_max
            )

        # è£æ­»æ¨¡å¼å€æ•¸ (threshold_multiplier)
        if 'threshold_multiplier' in self.param_bounds:
            tm_min, tm_max = self.param_bounds['threshold_multiplier']
            tm_lower = max(tm_min, params.get('limit_multiplier', 5.0) * 1.5)
            if tm_lower >= tm_max:
                tm_lower = tm_min
            params['threshold_multiplier'] = trial.suggest_float(
                'threshold_multiplier', tm_lower, tm_max
            )

        try:
            result = self._run_backtest(params)

            duration = time.time() - start_time
            metrics = {
                'return_pct': result.return_pct,
                'sharpe_ratio': result.sharpe_ratio,
                'max_drawdown': result.max_drawdown,
                'trades_count': result.trades_count,
                'win_rate': result.win_rate,
            }

            trial_result = TrialResult(
                trial_number=trial.number,
                params=params.copy(),
                metrics=metrics,
                objective_value=result.sharpe_ratio,  # ç”¨ Sharpe ä½œç‚ºä¸»è¦æŒ‡æ¨™
                duration=duration
            )
            self._trials.append(trial_result)

            # è¿”å›ä¸‰å€‹ç›®æ¨™: (Sharpe, -å›æ’¤, æ”¶ç›Š)
            # Optuna é»˜èªæœ€å°åŒ–ï¼Œæ‰€ä»¥ Sharpe å’Œæ”¶ç›Šè¦å–è² 
            return (
                -result.sharpe_ratio,      # æœ€å¤§åŒ– Sharpe
                result.max_drawdown,       # æœ€å°åŒ–å›æ’¤
                -result.return_pct         # æœ€å¤§åŒ–æ”¶ç›Š
            )

        except Exception as e:
            self.logger.warning(f"Trial {trial.number} å¤±æ•—: {e}")
            return (1e6, 1e6, 1e6)

    def optimize(
        self,
        n_trials: int = 100,
        objective: OptimizationObjective = OptimizationObjective.SHARPE,
        method: OptimizationMethod = OptimizationMethod.TPE,
        n_startup_trials: int = 10,
        timeout: Optional[int] = None,
        n_jobs: int = 1,
        progress_callback: Callable[[int, int, float], None] = None,
        show_progress: bool = True
    ) -> SmartOptimizationResult:
        """
        åŸ·è¡Œæ™ºèƒ½å„ªåŒ–

        Args:
            n_trials: è©¦é©—æ¬¡æ•¸
            objective: å„ªåŒ–ç›®æ¨™
            method: å„ªåŒ–æ–¹æ³•
            n_startup_trials: éš¨æ©Ÿæ¡æ¨£æ¬¡æ•¸ (ç”¨æ–¼ TPE åˆå§‹åŒ–)
            timeout: è¶…æ™‚æ™‚é–“ (ç§’)
            n_jobs: ä¸¦è¡Œæ•¸
            progress_callback: é€²åº¦å›èª¿ (current, total, best_value)
            show_progress: æ˜¯å¦é¡¯ç¤ºé€²åº¦

        Returns:
            SmartOptimizationResult
        """
        if not OPTUNA_AVAILABLE:
            raise ImportError("è«‹å®‰è£ Optuna: pip install optuna")

        start_time = time.time()
        self._trials = []
        self._best_value = float('-inf')
        self._convergence = []

        self.logger.info(f"é–‹å§‹æ™ºèƒ½å„ªåŒ–: æ–¹æ³•={method.value}, ç›®æ¨™={objective.value}, è©¦é©—æ•¸={n_trials}")

        # é¸æ“‡æ¡æ¨£å™¨
        if method == OptimizationMethod.TPE:
            sampler = TPESampler(
                n_startup_trials=n_startup_trials,
                multivariate=True,
                seed=42
            )
        elif method == OptimizationMethod.NSGA_II:
            sampler = NSGAIISampler(seed=42)
        elif method == OptimizationMethod.NSGA_III:
            sampler = NSGAIIISampler(seed=42)
        else:
            sampler = TPESampler(n_startup_trials=n_startup_trials, seed=42)

        # å‰ªæå™¨ (æ—©æœŸåœæ­¢)
        pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=0)

        # å¤šç›®æ¨™å„ªåŒ–
        if objective == OptimizationObjective.MULTI_OBJECTIVE:
            study = optuna.create_study(
                directions=['minimize', 'minimize', 'minimize'],
                sampler=sampler if method in [OptimizationMethod.NSGA_II, OptimizationMethod.NSGA_III]
                        else NSGAIISampler(seed=42)
            )

            if show_progress:
                optuna.logging.set_verbosity(optuna.logging.WARNING)

            study.optimize(
                self._multi_objective,
                n_trials=n_trials,
                timeout=timeout,
                n_jobs=n_jobs,
                show_progress_bar=show_progress
            )

            # æå– Pareto å‰æ²¿
            pareto_front = []
            for trial in study.best_trials:
                pareto_front.append({
                    'params': trial.params,
                    'sharpe': -trial.values[0],
                    'max_drawdown': trial.values[1],
                    'return_pct': -trial.values[2],
                })

            # é¸æ“‡æœ€ä½³ (åŸºæ–¼ Sharpe)
            best_trial = max(study.best_trials, key=lambda t: -t.values[0])
            best_params = best_trial.params
            best_metrics = {
                'sharpe_ratio': -best_trial.values[0],
                'max_drawdown': best_trial.values[1],
                'return_pct': -best_trial.values[2],
            }

        else:
            # å–®ç›®æ¨™å„ªåŒ–
            study = optuna.create_study(
                direction='maximize',
                sampler=sampler,
                pruner=pruner
            )

            if show_progress:
                optuna.logging.set_verbosity(optuna.logging.WARNING)

            # è‡ªå®šç¾©å›èª¿
            def callback(study, trial):
                if progress_callback:
                    progress_callback(
                        trial.number + 1,
                        n_trials,
                        study.best_value if study.best_trial else 0
                    )

            study.optimize(
                lambda trial: self._optuna_objective(trial, objective),
                n_trials=n_trials,
                timeout=timeout,
                n_jobs=n_jobs,
                show_progress_bar=show_progress,
                callbacks=[callback] if progress_callback else None
            )

            pareto_front = None
            best_params = study.best_params
            best_trial_obj = self._trials[study.best_trial.number] if self._trials else None
            best_metrics = best_trial_obj.metrics if best_trial_obj else {}

        self._study = study

        # è¨ˆç®—åƒæ•¸é‡è¦æ€§
        param_importance = {}
        try:
            importance = optuna.importance.get_param_importances(study)
            param_importance = dict(importance)
        except Exception:
            # å¦‚æœç„¡æ³•è¨ˆç®—ï¼Œä½¿ç”¨åŸºæ–¼æ–¹å·®çš„ç°¡åŒ–ç‰ˆæœ¬
            param_importance = self._calculate_variance_importance()

        optimization_time = time.time() - start_time

        result = SmartOptimizationResult(
            best_params=best_params,
            best_metrics=best_metrics,
            best_objective=study.best_value if hasattr(study, 'best_value') else self._best_value,
            all_trials=self._trials,
            param_importance=param_importance,
            pareto_front=pareto_front,
            convergence_history=self._convergence,
            optimization_time=optimization_time,
            n_trials=len(self._trials),
            method=method.value,
            objective_type=objective.value
        )

        self.logger.info(f"å„ªåŒ–å®Œæˆ: è€—æ™‚ {optimization_time:.1f}s, æœ€ä½³ç›®æ¨™å€¼={result.best_objective:.4f}")

        return result

    def _calculate_variance_importance(self) -> Dict[str, float]:
        """åŸºæ–¼æ–¹å·®è¨ˆç®—åƒæ•¸é‡è¦æ€§ (å‚™ç”¨æ–¹æ³•)"""
        if not self._trials:
            return {}

        df = pd.DataFrame([t.to_dict() for t in self._trials])
        importance = {}

        for param in ['take_profit_spacing', 'grid_spacing', 'limit_multiplier', 'threshold_multiplier']:
            col = f'param_{param}'
            if col in df.columns:
                # è¨ˆç®—åƒæ•¸å€¼èˆ‡ç›®æ¨™å€¼çš„ç›¸é—œæ€§
                corr = abs(df[col].corr(df['objective']))
                importance[param] = corr if not np.isnan(corr) else 0.0

        # æ­£è¦åŒ–
        total = sum(importance.values())
        if total > 0:
            importance = {k: v/total for k, v in importance.items()}

        return importance

    def quick_optimize(
        self,
        n_trials: int = 50,
        objective: str = "sharpe"
    ) -> SmartOptimizationResult:
        """
        å¿«é€Ÿå„ªåŒ– (ä¾¿æ·æ–¹æ³•)

        Args:
            n_trials: è©¦é©—æ¬¡æ•¸
            objective: å„ªåŒ–ç›®æ¨™ ("return", "sharpe", "sortino", "calmar", "risk_adjusted")

        Returns:
            SmartOptimizationResult
        """
        obj_map = {
            "return": OptimizationObjective.RETURN,
            "sharpe": OptimizationObjective.SHARPE,
            "sortino": OptimizationObjective.SORTINO,
            "calmar": OptimizationObjective.CALMAR,
            "profit_factor": OptimizationObjective.PROFIT_FACTOR,
            "risk_adjusted": OptimizationObjective.RISK_ADJUSTED,
            "multi": OptimizationObjective.MULTI_OBJECTIVE,
        }

        objective_enum = obj_map.get(objective.lower(), OptimizationObjective.SHARPE)

        return self.optimize(
            n_trials=n_trials,
            objective=objective_enum,
            method=OptimizationMethod.TPE,
            n_startup_trials=min(10, n_trials // 5),
            show_progress=True
        )

    def get_study(self) -> Optional['optuna.Study']:
        """ç²å– Optuna Study å°è±¡ (ç”¨æ–¼é€²éšåˆ†æ)"""
        return self._study

    def save_results(self, filepath: str, result: SmartOptimizationResult):
        """ä¿å­˜å„ªåŒ–çµæœ"""
        data = {
            'best_params': result.best_params,
            'best_metrics': result.best_metrics,
            'best_objective': result.best_objective,
            'param_importance': result.param_importance,
            'optimization_time': result.optimization_time,
            'n_trials': result.n_trials,
            'method': result.method,
            'objective_type': result.objective_type,
            'convergence_history': result.convergence_history,
            'trials': [t.to_dict() for t in result.all_trials]
        }

        with open(filepath, 'w') as f:
            json.dump(data, f, indent=2, default=str)

        self.logger.info(f"çµæœå·²ä¿å­˜è‡³ {filepath}")


# === ä¾¿æ·å‡½æ•¸ ===

def smart_optimize_grid(
    df: pd.DataFrame,
    base_config: Config = None,
    n_trials: int = 100,
    objective: str = "sharpe",
    progress_callback: Callable = None
) -> SmartOptimizationResult:
    """
    æ™ºèƒ½ç¶²æ ¼å„ªåŒ–ä¾¿æ·å‡½æ•¸

    Args:
        df: Kç·šæ•¸æ“š
        base_config: åŸºç¤é…ç½®
        n_trials: è©¦é©—æ¬¡æ•¸
        objective: å„ªåŒ–ç›®æ¨™
        progress_callback: é€²åº¦å›èª¿

    Returns:
        SmartOptimizationResult
    """
    optimizer = SmartOptimizer(df, base_config)

    obj_map = {
        "return": OptimizationObjective.RETURN,
        "sharpe": OptimizationObjective.SHARPE,
        "sortino": OptimizationObjective.SORTINO,
        "calmar": OptimizationObjective.CALMAR,
        "risk_adjusted": OptimizationObjective.RISK_ADJUSTED,
    }

    return optimizer.optimize(
        n_trials=n_trials,
        objective=obj_map.get(objective.lower(), OptimizationObjective.SHARPE),
        method=OptimizationMethod.TPE,
        progress_callback=progress_callback
    )


# === æ¸¬è©¦ ===

if __name__ == "__main__":
    # æ¸¬è©¦æ™ºèƒ½å„ªåŒ–å™¨
    from .data_loader import DataLoader

    print("è¼‰å…¥æ•¸æ“š...")
    loader = DataLoader()
    df = loader.load("XRPUSDC", "2025-11-01", "2025-11-30")

    print("\né–‹å§‹æ™ºèƒ½å„ªåŒ–...")
    optimizer = SmartOptimizer(df)
    result = optimizer.quick_optimize(n_trials=30, objective="sharpe")

    print("\n" + str(result))
